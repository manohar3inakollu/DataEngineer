{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d48d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "config('spark.ui.port','0'). \\\n",
    "config(\"spark.sql.warehouse.dir\", f\"/user/itv014453/warehouse\"). \\\n",
    "enableHiveSupport(). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313fe144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WritePySparkcodetocreateanewdataframewiththedatagivenbelowhaving2columns(‘season’)and(‘windspeed’).[Datatypesofthecolumnnamescanbeinferred] \n",
    "data = [(\"Spring\",12.3),(\"Summer\",10.5),(\"Autumn\",8.2),(\"Winter\",15.1)]\n",
    "data_schema = ['season','windspeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28e40294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|season|windspeed|\n",
      "+------+---------+\n",
      "|Spring|     12.3|\n",
      "|Summer|     10.5|\n",
      "|Autumn|      8.2|\n",
      "|Winter|     15.1|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df = spark.createDataFrame(data,data_schema).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f87a58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"library_name\": \"Central Library\",\"location\": \"City Center\",\"books\": [{\"book_id\": \"B001\",\"book_name\": \"The Great Gatsby\",\"author\": \"F. Scott Fitzgerald\",\"copies_available\": 5},{\"book_id\": \"B002\",\"book_name\": \"To Kill a Mockingbird\",\"author\": \"Harper Lee\",\"copies_available\": 3}],\"members\": [{\"member_id\": \"M001\",\"member_name\": \"John Smith\",\"age\": 28,\"books_borrowed\": [\"B001\"]},{\"member_id\": \"M002\",\"member_name\": \"Emma Johnson\",\"age\": 35,\"books_borrowed\": []}]},\n",
      "{\"library_name\": \"Community Library\",\"location\": \"Suburb\",\"books\": [{\"book_id\": \"B003\",\"book_name\": \"1984\",\"author\": \"George Orwell\",\"copies_available\": 2},{\"book_id\": \"B004\",\"book_name\": \"Pride and Prejudice\",\"author\": \"Jane Austen\",\"copies_available\": 4}],\"members\": [{\"member_id\": \"M003\",\"member_name\": \"Michael Brown\",\"age\": 42,\"books_borrowed\": [\"B003\",\"B004\"]},{\"member_id\": \"M004\",\"member_name\": \"Sophia Davis\",\"age\": 31,\"books_borrowed\": [\"B004\"]}]}\n"
     ]
    }
   ],
   "source": [
    "#Considerthelibrarymanagementdatasetlocatedatthefollowingpath(/public/trendytech/datasets/library_data.json).UsingPySpark,loadthedataintoaDataframeandenforceschemausingStructType.\n",
    "!hadoop fs -head /public/trendytech/datasets/library_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a190cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "library_schema = StructType([\n",
    "    StructField('library_name',StringType()),\n",
    "    StructField('location',StringType()),\n",
    "    StructField('books',ArrayType(\n",
    "        StructType([\n",
    "            StructField('book_id',StringType()),\n",
    "            StructField('book_name',StringType()),\n",
    "            StructField('author',StringType()),\n",
    "            StructField('copies_available',IntegerType())\n",
    "        ])\n",
    "    )),\n",
    "    StructField('members',ArrayType(\n",
    "        StructType([\n",
    "            StructField('member_id',StringType()),\n",
    "            StructField('member_name',StringType()),\n",
    "            StructField('age',IntegerType()),\n",
    "            StructField('books_borrowed',ArrayType(StringType()))\n",
    "        ])\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f49d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_df = spark.read.schema(library_schema).json(\"/public/trendytech/datasets/library_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7296414d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- library_name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- books: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- book_id: string (nullable = true)\n",
      " |    |    |-- book_name: string (nullable = true)\n",
      " |    |    |-- author: string (nullable = true)\n",
      " |    |    |-- copies_available: integer (nullable = true)\n",
      " |-- members: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- member_id: string (nullable = true)\n",
      " |    |    |-- member_name: string (nullable = true)\n",
      " |    |    |-- age: integer (nullable = true)\n",
      " |    |    |-- books_borrowed: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc293bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Giventhedataset(/public/trendytech/datasets/train.csv),createaDataframeusingPySparkandperformthefollowingoperations\n",
    "#a)Dropthecolumnspassenger_nameandagefromthedataset.\n",
    "#b)Countthenumberofrowsafterremovingduplicatesofcolumnstrain_numberandticket_number.\n",
    "#c)Countthenumberofuniquetrainnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f43697f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_number,train_name,seats_available,passenger_name,age,ticket_number,seat_number\n",
      "123,Express,100,John,25,T123,A1\n",
      "123,Express,100,Emma,30,T124,B2\n",
      "456,Superfast,150,Michael,35,T125,C3\n",
      "456,Superfast,150,Sophia,40,T126,D4\n",
      "789,Local,50,William,28,T127,E5\n",
      "789,Local,50,Sophia,32,T128,F6\n",
      "789,Local,50,Oliver,45,T129,G7\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -head /public/trendytech/datasets/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a2f5199",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = spark.read.csv(\"/public/trendytech/datasets/train.csv\",inferSchema=\"true\",header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3922a57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- train_number: integer (nullable = true)\n",
      " |-- train_name: string (nullable = true)\n",
      " |-- seats_available: integer (nullable = true)\n",
      " |-- passenger_name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- ticket_number: string (nullable = true)\n",
      " |-- seat_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "817090fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_drop = train_df.drop(\"passenger_name\",\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0929786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+---------------+-------------+-----------+\n",
      "|train_number|train_name|seats_available|ticket_number|seat_number|\n",
      "+------------+----------+---------------+-------------+-----------+\n",
      "|         123|   Express|            100|         T123|         A1|\n",
      "|         123|   Express|            100|         T124|         B2|\n",
      "|         456| Superfast|            150|         T125|         C3|\n",
      "|         456| Superfast|            150|         T126|         D4|\n",
      "|         789|     Local|             50|         T127|         E5|\n",
      "|         789|     Local|             50|         T128|         F6|\n",
      "|         789|     Local|             50|         T129|         G7|\n",
      "+------------+----------+---------------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_drop.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83712624",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_drop_duplicates = train_drop.dropDuplicates([\"train_number\",\"ticket_number\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c72a763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_drop_duplicates.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c804a685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_drop_duplicates.select(\"train_name\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30934ae",
   "metadata": {},
   "source": [
    "##YouareworkingasaDataEngineerinalargeretailcompany.Thecompanyhasadatasetnamed\"sales_data.json\"thatcontainssalesrecordsfromvariousstores.\n",
    "##ThedatasetisstoredinJSONformatandmayhavesomecorruptormalformedrecordsduetooccasionaldataqualityissues.\n",
    "##Yourtaskistoreadthe\"sales_data.json\"dataset(/public/trendytech/datasets/sales_data.json)usingPySpark,utilizingdifferentreadmodestohandlecorruptrecords.\n",
    "##YouneedtocreateaDataframeusingpysparkandperformthefollowingoperations:\n",
    "##1.Readthedatasetusingthe\"permissive\"modeandcountthenumberofrecordsread.\n",
    "##2.Readthedatasetusingthe\"dropmalformed\"modeanddisplaythenumberofmalformedrecords.\n",
    "##3.Readthedatasetusingthe\"failfast\"mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78323094",
   "metadata": {},
   "source": [
    "!hadoop fs -head /public/trendytech/datasets/sales_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b66e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"store_id integer,product string,quantity integer,revenue double\"\n",
    "sales_data_df = spark.read.schema(schema).json(\"/public/trendytech/datasets/sales_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05d985bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10d1f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data_df_2 = spark.read.schema(schema).option(\"mode\",\"dropmalformed\").json(\"/public/trendytech/datasets/sales_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "582c26a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data_df_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8adcde06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data_df_3 = spark.read.schema(schema).option(\"mode\",\"failfast\").json(\"/public/trendytech/datasets/sales_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5912d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data_df_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ceaca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
